---
title: 'Blog 4: Incumbency'
author: Meredith Zielonka
date: '2022-09-29'
slug: []
categories: []
tags: []
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at Harvard University taught by Professor Ryan D. Enos.*

# Introduction

This week in Election Analytics, we will be incorporating incumbency and expert predictions into our existing models.

Incumbency is widely considered to have an impact in elections. In recent years, analysts have looked deeper into this, identifying two types of incumbent impact: President's Party and district-level incumbency. On a district level, many have speculated that voters may reward or punish incumbency for various reasons. [Adam Brown asserts](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/ECFE39E003912F8AF65C2AD14A34BD8C/S2052263014000062a.pdf/div-class-title-voters-don-t-care-much-about-incumbency-div.pdf), however, that voters actually do not care about the incumbent candidate. Rather, incumbency inherently enables structural advantages that favor the incumbent. For example, the incumbent has the ability to reward their district with "pork," or economic benefits.

The President's party tends to lose seats during congressional midterm elections, because this election is generally seen as a referendum on the president. [Folke and Snyder](https://onlinelibrary-wiley-com.ezp-prod1.hul.harvard.edu/doi/pdfdirect/10.1111/j.1540-5907.2012.00599.x) explored this phenomenon through the lens of gubernatorial elections, ultimately finding that the party of the governor does experience losses. Folke and Snyder attributed some of these results to poor economic performance and other factors. They also ruled out reversion to the mean as the cause of the loss, indicating that it should also not be considered as much on a national level.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Loading in necessary libraries
library(tidyverse)
library(janitor)
library(stargazer)
library(tidyverse)
require(ggplot2)
require(sf)
library(usmap)
library(ggmap)
library(rmapshaper)
library(blogdown)

# Reading in the data
expert_ratings <- read_csv("expert_rating.csv")
historical_results <- read_csv("house party vote share by district 1948-2020.csv") %>% 
  clean_names()
```

Turning to my work this week: First, I attempted to evaluate the accuracy of expert predictions. Expert predictions are generated by well-known election predictors and polling houses in order to provide data for their own prediction models. They are effectively refined polling data but they also take into account the fundamentals such as GDP, incumbency, and district-specific information. 

# Expert Predictions

In order to compare the accuracy of the predictions, I created two maps, one of 2018 Democratic voteshare and one of the average expert ratings, where 7 is Solid R and 1 is Solid D. The issue with this is immediately obvious. We are missing so much data that the expert predictions are almost useless as a basis for anything except swing districts. From the little data we have, the average expert ratings seem to align with voteshare. Districts with lower Democratic voteshares are more likely to be shaded closer to a tossup or lean Republican. However, in a prediction, this data would only be useful in tandem with polls on the districts that don't have expert predictions, and data on safety districts.

```{r cleaning the data}

# Merge on year
# Change in GDP, whether incumbent, expert ratings
 
nums <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
historical_results$district_num <- 
  ifelse(historical_results$district_num %in% nums, 
              paste0("0", historical_results$district_num),
              historical_results$district_num)

historical_results$st_fips <- 
  ifelse(historical_results$st_fips %in% nums, 
                  paste0("0", historical_results$st_fips), 
                  historical_results$st_fips)

avg_ratings <- expert_ratings %>% 
  select(year, state, district, avg_rating)

dem_results <- historical_results %>% 
  select(race_year, state, area, dem_votes_major_percent, dem_status, rep_status, third_status, st_fips, district_num) %>%
  rename("year" = "race_year") %>% 
  separate(area, into = c("area", "district"), sep = " ") %>% 
  select(-area) %>% 
  mutate(district = case_when(
    district == "Large" ~ "AL",
    TRUE ~ district
    ))

# code new incumbent variable
dem_results <- dem_results %>%
               mutate(incumbent = case_when(
    dem_status == "Incumbent" ~ 1,
    dem_status == "Challenger" ~ 0,
    dem_status == NA ~ 0,
    rep_status == "Incumbent" ~ 0,
    rep_status == "Challenger" ~ 0,
    third_status == "Incumbent" ~ 0,
    third_status == "Challenger" ~ 0))

histratings <- left_join(dem_results, avg_ratings, by = c("year", "state", "district")) 

hist2018results <- histratings %>%
  filter(year == 2018)

ratings2018 <- hist2018results %>% 
  rename(DISTRICT = district, STATENAME = state)

cd116 <- st_read("districtShapes/districts114.shp", quiet = TRUE)
# join election returns with shapefiles
cd116 <- cd116 %>% left_join(ratings2018, by=c("DISTRICT", "STATENAME"))

districts_simp <- rmapshaper::ms_simplify(cd116, keep = 0.01)

# plot for actual 2018 voteshare
ggplot() +
  geom_sf(data = districts_simp, aes(fill = dem_votes_major_percent, geometry = geometry),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient(low = "white", high = "blue", limits = c(0, 100)) +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "The 2018 Election Democratic Vote Share by District and State", col = "Dem") +
  theme(axis.title.x=element_blank(),
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())

# plot for expert predictions on lean
ggplot() +
  geom_sf(data = districts_simp, aes(fill = avg_rating, geometry = geometry),
          inherit.aes = FALSE, alpha = 0.9) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 4, limits = c(0, 7)) +
  theme_void() + 
  coord_sf(xlim = c(-172.27, -66.57), ylim = c(18.55, 71.23), expand = FALSE) + 
  labs(title = "The 2018 Election Expert Predictions for Democratic Lean", col = "Range") +
  theme(axis.title.x=element_blank(),
      axis.text.x=element_blank(),
      axis.ticks.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks.y=element_blank())

```
# Modelling

For my predictive model, I initially planned to regress on polls, economic data, expert predictions and incumbency. However, I wished to avoid accidentally overfitting my model so I cut out the economic data, considering that expert predictions often take it into account already. 

I planned to join polling data with the expert prediction data in order to enhance my model like I evaluated above, however I ran into many issues with missing data so I decided that it would be more productive to predict solely the swing districts established by the expert predictions. 

```{r}
polls <- read_csv("dist_polls_2018-2022.csv")

# subset
polls_df <- polls %>%
  select(party, candidate_name, pct, st_fips, cd_fips, cycle) %>%
  rename("year" = "cycle") %>% 
  rename("district_num" = "cd_fips") %>% # for merging
  filter(party == "DEM", year != 2022)

# join by 'year'
# fulldat <- fulldat %>% 
#  left_join(histratings, polls_df, by = c("st_fips", "district_num", "year")) %>% 
#  select(year, state, district, dem_votes_major_percent, incumbent, avg_rating, pct)

# Joining the data and nesting by state and district
train_data <- avg_ratings %>% 
  filter(year != 2022) %>% 
  # left join as there aren't ratings for every district
  left_join(dem_results, by = c("year", "state", "district")) %>% 
  group_by(state, district) %>% 
  filter(n() > 1) %>% # Filtering out single data rows
  group_nest() %>% 
  mutate(data = map(data, ~unnest(., cols = c())))

test_data <- avg_ratings %>% 
  filter(year == 2022) %>% 
  group_by(state, district) %>% 
  group_nest() %>% 
  mutate(data = map(data, ~unnest(., cols = c())))

```
Finally, I also wanted to use incumbency in the regression but I ran into issues with the scope of the data set and lack of incumbency data for 2022 so for now, I'm relying on the incumbency that has already been worked into the expert predictions and in future posts, I will make it stand out a bit more in accordance with Adam Brown.

```{r models}
# Building MEDIOCRE models
models <- train_data %>% 
  mutate(model = map(data, ~lm(dem_votes_major_percent ~ avg_rating, 
                                  data = .x))) %>% 
  select(-data)

# Extracting model results
model_results <- models %>% 
  mutate(r_squared = map_dbl(model, ~summary(.x)$r.squared))

# Predicting 2022 with a model
pred_2022 <- test_data %>%
  # inner join as there may not be historical models for some districts
  inner_join(models, by = c("state", "district")) %>% 
  mutate(pred = map_dbl(.x = model, .y = data, ~predict(object = .x, newdata = as.data.frame(.y)))) %>%
  select(state, district, pred)

print(pred_2022)
```
# Conclusion

Frankly, this week was a lot of trial and error. The predictions for the swing states are not horrible. The R-Squareds range from perfect 1 (probably in uncontested races) to .03 but the vast majority are in the .7-.9 range. I would rely on these given dire circumstances.
