---
title: 'Blog Post 3: Polling'
author: Meredith Zielonka
date: '2022-09-22'
slug: []
categories: []
tags: []
---

*This blog is part of a series related to Gov 1347: Election Analytics, a course at Harvard University taught by Professor Ryan D. Enos.*

# Introduction

This week in Election Analytics, the subject of discussion is Polling. How do polls impact election predictions? Are they reliable? How should they be weighed when compared to other factors like the fundamentals, or economy-based predictions? Before diving into my model and this week's adjustments, let's break down the work of some more experienced pollsters.

Nate Silver became almost a household name in 2008 after he successfully predicted the outcome of the presidential election in 49 out of 50 states. His blog, FiveThirtyEight, has since become a leading election prediction model, taking into consideration a wide variety of factors. [FiveThirtyEight](https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/) takes the attitude that if it isn't broken, don't fix it. They have been slightly altering the same model for years, rather than creating a new model each year. They also use nearly identical models for their House, Senate, and gubernatorial races, predicating the results for all of them on localized data rather than the statewide and national data used for presidential elections. In 1907, Francis Galton proved the wisdom of the crowds, where the mean among a large group of guesses is likely to be close to the correct answer. Silver takes this to heart and relies less on polling when the quantity of polling is few or the quality of the polling is less reliable. Silver also makes many post-game adjustments to his models, accounting for likely voters, statistical bias, and timeline. Finally, a recent comment from FiveThirtyEight notes that their recent testing has shown that partisanship and generic ballot should have more influence than other fundamentals like incumbency.

G. Elliott Morris is a data journalist for the Economist. He also manages the Economist's [election prediction model](https://projects.economist.com/us-2020-forecast/house). Much like FiveThirtyEight, the Economist's model takes into consideration polls, partisan lean, incumbency, the economy, and fundraising. Compared to Silver, however, Morris does not seem to apply the same frequent adjustments to his model (or at least does not describe them in his explanation). Morris is very aware of the tendency to over-fit models and consciously avoids this, through both cross-validation and, it seems, fewer manual adjustments. Morris also weighs polls differently than Silver. While Silver seems to calibrate polls against each other if one is consistently above or below the others, the Economist lends less weight overall to pollsters that tend to over or underestimate. 

While both of these approaches are valid and lead to accurate results, I tend to favor Morris. While I prefer FiveThirtyEight's attention to partisanship and their method of calibrating polls against each other, they seem to engage in too much manual adjustment and overfitting that seems unnecessary or misleading. I will be taking these ideas into consideration as I assemble my own model.

# Modeling

Last week, I found that economic factors are a solid base for a prediction, though not a good sole factor to rely on. I decided that this was enough to warrant including economic factors in my model this week. However, I chose to use GDP over RDI because my model responded better to it during testing. In order to create this week's model, I modified, selected, grouped, summarised, and spread datasets containing generic poll results, economic factors, and popular vote margins for 1950 through 2020. Based on Gelman and King's article describing how polls conducted further in advance of the election are often more accurate, I also filtered the polling data to focus on polls conducted more than 90 days before election day. Finally, I was able to create a data frame for modeling and graphing. I regressed Incumbent Party Vote Share on a combination of Incumbent Average Support in generic polls and GDP growth percent. I calculated regressions for all the data together and I split it up between cases where the incumbent party won and lost. 

Below, you will find two graphs, one showing the different regressions for incumbent win versus challenger win, and the other showing the regression line for all of the data together. The second graph marks in green the challenger wins.

In the first graph, neither incumbent wins nor challenger wins seem to be particularly well-correlated. In the second, the correlation seems weak but still stronger than the split set. The stargazer results back this up.  The adjusted r-squared value of the incumbent-win-only regression is abysmal at 0.04815, indicating basically no correlation. The challenger-win-only regression is much stronger at 0.2001, though this would typically not be considered a strong correlation to rely on for predictions. The regression for all of the data together proved to have a stronger correlation than either of the subsets, with an adjusted r-squared value of 0.3236. This regression also had an extremely low p-value.

```{r, echo = FALSE, results = 'hide'}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(ggplot2)
library(stargazer)
library(blogdown)

## read in data 
popvote_df <- read_csv("house_popvote_seats copy.csv")
economy_df <- read_csv("Copy of GDP_quarterly.csv")
polls_df    <- read_csv("polls_df.csv")

winterpolls <- polls_df %>% 
                  filter(days_until_election >= 90) %>% 
                  group_by(year, party) %>% 
                  summarise(avg_support = mean(support)) %>% 
                  spread(key = "party", value = "avg_support")

datpollpop <- popvote_df %>% 
    inner_join(winterpolls)

economyfiltered <- economy_df %>% 
                  filter(quarter_cycle == 6) %>% 
                  select("year", "GDP_growth_qt", "GDP_growth_pct")

dat <- datpollpop %>% 
    left_join(economyfiltered)

# create variable of support for incumbent
dat <- dat %>% mutate(H_incumbent_avg_support = ifelse(H_incumbent_party == "R", dat$R, dat$D))

## model - fundamentals + polls
dat_plus <- dat
dat_plus_inc <- dat_plus[dat_plus$H_incumbent_party_winner == TRUE,]
dat_plus_chl <- dat_plus[!dat_plus$H_incumbent_party_winner == TRUE,]

mod_dat_plus <- lm(H_incumbent_party_majorvote_pct ~ H_incumbent_avg_support + GDP_growth_pct, data = dat_plus)
mod_plus_inc <- lm(H_incumbent_party_majorvote_pct ~ H_incumbent_avg_support + GDP_growth_pct, data = dat_plus_inc)
mod_plus_chl <- lm(H_incumbent_party_majorvote_pct ~ H_incumbent_avg_support + GDP_growth_pct, data = dat_plus_chl)

# summary(mod_dat_plus) #r2 0.3236
# summary(mod_plus_inc) # 0.04815
# summary(mod_plus_chl) # 0.2001

stargazer(mod_dat_plus)
stargazer(mod_plus_inc)
stargazer(mod_plus_chl)

dat_plus %>% 
   ggplot(aes(x = (H_incumbent_avg_support + GDP_growth_pct),
             y=H_incumbent_party_majorvote_pct,
             label = year, color = ifelse(dat_plus$H_incumbent_party_winner == TRUE, "purple", "green4"))) + 
    geom_text(size = 4) +
    geom_smooth(method="lm", formula = y ~ x) +
    xlab("Incumbent Support and GDP") +
    ylab("Incumbent Party PV") +
    theme_bw() +
    ggtitle("Incumbent Average Support", subtitle = "Blue is when incumbents won and red is when challengers won.") + 
    theme(axis.text = element_text(size = 12),
          axis.title = element_text(size = 14),
          plot.title = element_text(size = 18),
          legend.position = c(55, 48)) +
    labs(color = "Incumbent Winner")

datreg <- dat_plus %>% 
   ggplot(aes(x = (H_incumbent_avg_support + GDP_growth_pct),
             y=H_incumbent_party_majorvote_pct,
             label = year)) + 
    geom_text(size = 4, color = ifelse(dat_plus$H_incumbent_party_winner == TRUE, "purple", "green4")) +
    geom_smooth(method="lm", formula = y ~ x) +
    xlab("Incumbent Support and GDP") +
    ylab("Incumbent Party PV") +
    theme_bw() +
    ggtitle("Incumbent Average Support", subtitle = "Purple is when incumbents won and green is when challengers won.") + 
    theme(axis.text = element_text(size = 12),
          axis.title = element_text(size = 14),
          plot.title = element_text(size = 18),
          legend.position = c(55, 48)) +
    labs(color = "Incumbent Winner")

datreg
    
```
Despite its p-value, the regression on all of the data had relatively high residuals, sending mixed messages about the quality of the correlation. The regression on incumbent wins alone was not much better, but the regression on incumbent popular vote with a challenger win had a relatively low residual of about 1. This is important for our purposes because the most pressing question about the upcoming election is whether the Democrats will maintain their majority in Congress. If we can accurately predict the incumbent percent vote with a challenger win, we may be able to predict whether the Democrats will be unseated.

```{r, echo = FALSE, results = 'hide'}

# in-sample fit
mean(abs(mod_dat_plus$residuals))
mean(abs(mod_plus_inc$residuals))
mean(abs(mod_plus_chl$residuals))

# Predicting 2022
generic22_df  <- read_csv("538_generic_poll_2022.csv")
generic22filt <- generic22_df %>% 
  select("pollster", "samplesize", "dem", "rep") %>% 
  rename("sample_size" = "samplesize") %>% 
  mutate(year=2022)
pollsfiltered <- polls_df %>% 
  pivot_wider(names_from = "party", values_from = "support") %>% 
  select("pollster", "sample_size", "D", "R", "year") %>% 
  rename("dem" = "D") %>% 
  rename("rep" = "R")
genericballot <- full_join(generic22filt, pollsfiltered)

economy22 <- economy_df %>% 
                  filter(year == "2022", quarter_cycle == 6) %>% 
                  select("year", "GDP_growth_qt", "GDP_growth_pct")

dat22 <- generic22filt %>% 
    left_join(economy22)

demsupport <- mean(dat22$dem) # 43.67011
repsupport <- mean(dat22$rep) # 42.2899

dat_2022_inc <- data.frame(GDP_growth_pct = 2.034715644, avg_support = demsupport)
dat_2022_chl <- data.frame(GDP_growth_pct = 2.034715644, avg_support = repsupport)
dat_2022_all <- data.frame(GDP_growth_pct = 2.034715644, avg_support = (.5*(repsupport + demsupport)))


## point predictions
predict(mod_plus_inc, newdata = dat_2022_inc) # 53.06198
predict(mod_plus_chl, newdata = dat_2022_chl) # 48.23634
predict(mod_dat_plus, newdata = dat_2022_all) # 50.51226

## prediction intervals
(pred_plus_inc <- predict(mod_plus_inc, dat_2022_inc, 
                          interval = "prediction", level=0.95))
(pred_plus_chl <- predict(mod_plus_chl, dat_2022_chl, 
                          interval = "prediction", level=0.95))
(pred_dat_plus <- predict(mod_dat_plus, dat_2022_all, 
                          interval = "prediction", level=0.95))

pred_df <- rbind(
  data.frame(pred_plus_inc, model = "Plus", party="Republican"),
  data.frame(pred_plus_chl, model = "Plus", party="Democrat"))
ggplot(pred_df, 
       aes(x=party, y = fit, ymin=lwr, ymax=upr, color=model)) +
  geom_pointrange(position = position_dodge(width = 0.5)) + 
  theme_bw()

datreg +
geom_point(aes((2.034715644 + demsupport), predict(mod_plus_inc, newdata = dat_2022_inc)), colour = "blue")

```
Looking at the blue dot on the graph above, The final prediction based on this data is that the Democrats will win the popular vote at 53.06198, holding onto their majority. However, the upper and lower bounds on the graph of the model predictions do intersect, meaning that this prediction cannot be certain.
